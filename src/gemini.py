import os
from fastmcp import FastMCP
from google import genai
from google.genai import types


mcp = FastMCP("Gemini MCP Server")


@mcp.tool(
    description="Generates text using the Gemini AI model based on a given prompt."
)
def prompt(prompt_s: str) -> str:
    return _prompt(prompt_s)


def _prompt(prompt_s: str) -> str:
    """
    This function takes a prompt and returns text generated by the Gemini AI model.
    The API key and model name are read from environment variables (GEMINI_API_KEY and GEMINI_MODEL).

    Args:
        prompt: The prompt to send to the Gemini AI model.

    Returns:
        The text generated by the Gemini AI model.
    """
    key = os.environ.get("GEMINI_API_KEY")
    model_name = os.environ.get("GEMINI_MODEL", "gemini-1.5-flash")

    if not key:
        raise ValueError("GEMINI_API_KEY environment variable not set.")

    client = genai.Client(api_key=key)

    # Google Search 그라운딩 도구 정의
    grounding_tool = types.Tool(
        google_search=types.GoogleSearch()
    )

    # 생성 설정 구성
    config = types.GenerateContentConfig(
        tools=[grounding_tool]
    )

    # 요청 실행
    response = client.models.generate_content(
        model=model_name,
        contents=prompt_s,
        config=config,
    )

    retval = response.text
    print(f"Prompt: {prompt_s}\nModel: {model_name}\nResponse: {retval}")
    return retval


if __name__ == "__main__":
    mcp.run()
