import os
from fastmcp import FastMCP

mcp = FastMCP("Gemini MCP Server")

@mcp.tool(description="Generates text using the Gemini AI model based on a given prompt.")
def _prompt(prompt: str) -> str:
    """
    This function takes a prompt and returns text generated by the Gemini AI model.
    The API key and model name are read from environment variables (GEMINI_API_KEY and GEMINI_MODEL).

    Args:
        prompt: The prompt to send to the Gemini AI model.

    Returns:
        The text generated by the Gemini AI model.
    """
    key = os.environ.get("GEMINI_API_KEY")
    model = os.environ.get("GEMINI_MODEL", "gemini-1.5-flash")

    if not key:
        raise ValueError("GEMINI_API_KEY environment variable not set.")

    # In a real scenario, you would use a library like google-generativeai here.
    print(f"Prompt: {prompt}\nModel: {model}")
    return f"Generated text for: {prompt}"


def main():
    mcp.run()


if __name__ == "__main__":
    main()