import os
from fastmcp import FastMCP
from openai import OpenAI


mcp = FastMCP("Gemini MCP Server")

@mcp.tool(description="Generates text using the Gemini AI model based on a given prompt.")
def prompt(prompt_s: str) -> str:
    return _prompt(prompt_s)


def _prompt(prompt_s: str) -> str:
    """
    This function takes a prompt and returns text generated by the Gemini AI model.
    The API key and model name are read from environment variables (GEMINI_API_KEY and GEMINI_MODEL).

    Args:
        prompt: The prompt to send to the Gemini AI model.

    Returns:
        The text generated by the Gemini AI model.
    """
    key = os.environ.get("GEMINI_API_KEY")
    model = os.environ.get("GEMINI_MODEL", "gemini-2.0-flash")

    if not key:
        raise ValueError("GEMINI_API_KEY environment variable not set.")

    client = OpenAI(
        api_key=key,
        base_url="https://generativelanguage.googleapis.com/v1beta/"
    )
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt_s}]
    )

    retval = response.choices[0].message.content
    print(f"Prompt: {prompt_s}\nModel: {model}\nResponse: {retval}")
    return retval


if __name__ == "__main__":
    mcp.run()
